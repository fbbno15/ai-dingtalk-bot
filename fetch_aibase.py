import requests
from bs4 import BeautifulSoup

def fetch_latest_aibase_fulltext():
    # Step 1: æ‰“å¼€ç›®å½•é¡µ
    index_url = "https://www.aibase.com/zh/daily/"
    index_res = requests.get(index_url)
    index_soup = BeautifulSoup(index_res.text, "html.parser")

    # Step 2: æ‰¾ç¬¬ä¸€ä¸ªå« /zh/daily/ çš„æœ‰æ•ˆé“¾æ¥ï¼ˆæœ€æ–°æ—¥æŠ¥å…¥å£ï¼‰
    first_link_tag = next((a for a in index_soup.find_all('a', href=True) if '/zh/daily/' in a['href']), None)
    if not first_link_tag:
        return "âŒ æœªæ‰¾åˆ°æ—¥æŠ¥å…¥å£é“¾æ¥"

    relative_url = first_link_tag['href']
    full_url = "https://www.aibase.com" + relative_url

    # Step 3: æ‰“å¼€æ—¥æŠ¥è¯¦æƒ…é¡µ
    detail_res = requests.get(full_url)
    detail_soup = BeautifulSoup(detail_res.text, "html.parser")

    # Step 4: æå–æ­£æ–‡å†…å®¹
    content_div = detail_soup.select_one("div.break-all")
    if not content_div:
        return "âŒ æœªæ‰¾åˆ°æ—¥æŠ¥æ­£æ–‡å†…å®¹"

    text = content_div.get_text(separator="\n", strip=True)

    # Step 5: è¿”å›æ ¼å¼åŒ–å†…å®¹
    return f"""## ğŸ¤– AIæ—¥æŠ¥è‡ªåŠ¨æ¨é€ï¼ˆå…³é”®è¯è§¦å‘ï¼‰

{text}

ğŸ‘‰ [æŸ¥çœ‹åŸæ–‡]({full_url})"""
