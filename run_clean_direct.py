from playwright.sync_api import sync_playwright
import requests
import os,json
from bs4 import BeautifulSoup

def get_today_daily_url(list_url: str) -> str:
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page(user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
        page.goto(list_url)
        page.wait_for_timeout(8000)
        daily_link = page.locator('a:has-text("æŸ¥çœ‹æ—¥æŠ¥")').first.get_attribute("href")
        browser.close()
    if daily_link:
        if daily_link.startswith("/"):
            return "https://www.aibase.com" + daily_link
        else:
            return daily_link
    else:
        raise Exception("æœªæ‰¾åˆ°ä»Šæ—¥æ—¥æŠ¥é“¾æ¥")

def fetch_aibase_article_markdown(url: str) -> str:
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page(user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
        page.goto(url)
        page.wait_for_timeout(8000)
        html = page.content()
        browser.close()

    soup = BeautifulSoup(html, "html.parser")
    # æå–æ ‡é¢˜å’Œæ—¥æœŸ
    title = soup.find("h1")
    date = soup.find("time")
    title_text = title.get_text(strip=True) if title else "AIæ—¥æŠ¥"
    date_text = date.get_text(strip=True) if date else ""

    # æå–æ‰€æœ‰æ—¥æŠ¥æ¡ç›®
    items = []
    for strong in soup.find_all("strong"):
        strong_text = strong.get_text(strip=True)
        # åªæŠ“å–ä»¥æ•°å­—åŠ é¡¿å·å¼€å¤´çš„æ ‡é¢˜ï¼ˆå¦‚1ã€2ã€3...ï¼‰
        if strong_text and strong_text[0].isdigit() and 'ã€' in strong_text:
            item_title = strong_text
            # æ‰¾åˆ°ä¸‹ä¸€ä¸ª blockquote ä½œä¸ºæè¦
            blockquote = strong.find_next("blockquote")
            if blockquote:
                summary_lines = [line.strip() for line in blockquote.stripped_strings if line.strip()]
                items.append((item_title, summary_lines))

    # æ‹¼ Markdown
    md_content = f"# {title_text}\n\nğŸ—“ï¸ {date_text}\n\n## å†…å®¹æ‘˜è¦\n\n"
    for idx, (item_title, summary_lines) in enumerate(items, 1):
        md_content += f"## {item_title}\n"
        for line in summary_lines:
            md_content += f"Â· {line}\n"
        md_content += "\n"
    return md_content

def clean_with_gpt_azure(raw_markdown: str) -> str:
    url = 'https://api.openai.com/v1/chat/completions'
    api_key = os.getenv("OPENAI-KEY")
    print('api_key'+api_key+'====')
    Authorization = 'Bearer {0}'.format(api_key)
    headers = {'content-type': 'application/json','Authorization': Authorization}
    payload = {
        "messages": [
            {
                "role": "user",
                "content": f"""ä»¥ä¸‹æ˜¯ä» AIbase æŠ“å–çš„åŸå§‹æ—¥æŠ¥å†…å®¹ï¼ˆMarkdownï¼‰ï¼Œè¯·ä½ æŒ‰ç…§ä»¥ä¸‹æ¸…æ´—è§„åˆ™ä¸¥æ ¼æ‰§è¡Œï¼š\n\n
âœ… æ¸…æ´—è§„åˆ™æ±‡æ€»ï¼ˆä¸¥æ ¼æ‰§è¡Œï¼‰
1. åªä¿ç•™ä¸¤ç±»å†…å®¹ï¼š
â€¢ ç°æœ‰æ¨¡å‹æˆ–å·¥å…·çš„ã€Œè¿­ä»£å‡çº§ã€
â€¢ å…¨æ–°å¯ç”¨/å¯æµ‹è¯•çš„å·¥å…·ã€Œæ­£å¼å‘å¸ƒã€
2. åˆ é™¤æ‰€æœ‰é¢„æœŸ/å³å°†ä¸Šçº¿å†…å®¹ï¼ˆå¦‚"è®¡åˆ’æ¨å‡º""é¢„è®¡ä¸Šçº¿"ç­‰ï¼‰
3. ä¿ç•™æ‰€æœ‰å¸¦é“¾æ¥çš„å†…å®¹ï¼Œå³ä½¿å†…å®¹ä¸­ä½¿ç”¨äº†"é¢„è®¡"ç­‰è¯ï¼Œä¹Ÿä¸å‰”é™¤
4. åˆ é™¤æ‰€æœ‰"æ”¿ç­–ç±»"å†…å®¹
5. ä¸ä¿ç•™æ— é“¾æ¥ã€ä¸”ä¸ºé¢„æµ‹ã€æ¦‚å¿µé˜¶æ®µçš„å†…å®¹ï¼ˆè®°ä½ï¼Œä¸€å®šåˆ é™¤æ— é“¾æ¥å†…å®¹ï¼ï¼ï¼‰\n\n
âœ… å†…å®¹ç»“æ„ç­›é€‰
æ¯æ¡å†…å®¹åªä¿ç•™ï¼š
â€¢ ä¸€çº§æ ‡é¢˜ï¼ˆå³å†…å®¹æ ‡é¢˜ï¼‰
â€¢ æ ‡é¢˜ä¸‹æ–¹çš„ã€AiBaseæè¦ã€‘ä¸­çš„æ¯ä¸€æ¡ï¼ˆæ— æ­£æ–‡æ®µè½ã€æ— å›¾ç‰‡ã€æ— emojiï¼‰
â€¢ æè¦æ¯æ¡å‰åŠ ã€ŒÂ·ã€\n\n
âœ… ä»¥Markdownçš„å½¢å¼è¾“å‡ºç»™æˆ‘ï¼ŒMarkdownæ ¼å¼è§„èŒƒå¦‚ä¸‹ï¼š
# YYYY-MM-DD AIèµ„è®¯æ—¥æŠ¥\n\nä»Šå¤©å…± N æ¡èµ„è®¯\n\n### ğŸ’¡AIå·¥å…·æ–°åŠ¨æ€\n\n## æ ‡é¢˜\n\nÂ· æè¦å†…å®¹1  \nÂ· æè¦å†…å®¹2  \nÂ· æè¦å†…å®¹3  \n[è¯¦æƒ…é“¾æ¥](https://xxx)  \n#è¯é¢˜æ ‡ç­¾1 #è¯é¢˜æ ‡ç­¾2ï¼ˆä½œä¸ºæ­£æ–‡æ®µè½ï¼‰\n\nğŸ‘‰ğŸ»AI ä¸–ç•Œç¬æ¯ä¸‡å˜ï¼Œåœ¨è¯„è®ºåŒºç•™ä¸‹è§‚ç‚¹ï¼Œæˆ–æŠ•ç¨¿ä½ å…³æ³¨çš„å‰æ²¿é“¾æ¥ï¼Œè®©æ›´å¤šäººçœ‹åˆ°ä½ çš„è§†è§’ï¼\n\nåŸå§‹å†…å®¹å¦‚ä¸‹ï¼š\n{raw_markdown}
"""
            }
        ]
    }

    postdata = {'model': 'gpt-4o', 'messages': payload['messages'], 'temperature': 0, 'max_tokens': 3000, 'top_p': 1,
			'frequency_penalty': 0.5, 'presence_penalty': 0.5}
    data = json.dumps(postdata)
    response = requests.post(url, headers=headers, data=data)
    response.raise_for_status()
    return response.json()["choices"][0]["message"]["content"].strip()

if __name__ == "__main__":
    list_url = "https://www.aibase.com/zh/daily"
    today_url = get_today_daily_url(list_url)
    print(f"ä»Šæ—¥æ—¥æŠ¥é“¾æ¥ï¼š{today_url}")
    raw_md = fetch_aibase_article_markdown(today_url)
    print("âœ… å·²æŠ“å–åŸå§‹æ—¥æŠ¥å†…å®¹\n")

    cleaned_md = clean_with_gpt_azure(raw_md)
    print("\nâœ… ChatGPT æ¸…æ´—è¾“å‡ºå¦‚ä¸‹ï¼š\n")
    print(cleaned_md)

    # ä»¥æ—¥æŠ¥IDå‘½åä¿å­˜
    daily_id = today_url.rstrip('/').split('/')[-1]
    filename = f"aibase_{daily_id}_cleaned.md"
    with open(filename, "w", encoding="utf-8") as f:
        f.write(cleaned_md)
    print(f"âœ… å·²ä¿å­˜ä¸º {filename}")
